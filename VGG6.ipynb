{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPntVqr3WtgaqcCrbZmQQ2o"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import math\n","import torch.nn.init as init\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","import torch.optim as optim\n"],"metadata":{"id":"z3VbcO0DPumy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Data Loader**"],"metadata":{"id":"u3g5novTQyk6"}},{"cell_type":"code","source":["from PIL import Image, ImageEnhance, ImageOps\n","import random\n","import numpy as np\n","import torch\n","\n","\n","class Cutout(object):\n","    \"\"\"Randomly mask out one or more patches from an image.\n","    Args:\n","        n_holes (int): Number of patches to cut out of each image.\n","        length (int): The length (in pixels) of each square patch.\n","    \"\"\"\n","    def __init__(self, n_holes, length):\n","        self.n_holes = n_holes\n","        self.length = length\n","\n","    def __call__(self, img):\n","        \"\"\"\n","        Args:\n","            img (Tensor): Tensor image of size (C, H, W).\n","        Returns:\n","            Tensor: Image with n_holes of dimension length x length cut out of it.\n","        \"\"\"\n","        h = img.size(1)\n","        w = img.size(2)\n","\n","        mask = np.ones((h, w), np.float32)\n","\n","        for n in range(self.n_holes):\n","            y = np.random.randint(h)\n","            x = np.random.randint(w)\n","\n","            y1 = np.clip(y - self.length // 2, 0, h)\n","            y2 = np.clip(y + self.length // 2, 0, h)\n","            x1 = np.clip(x - self.length // 2, 0, w)\n","            x2 = np.clip(x + self.length // 2, 0, w)\n","\n","            mask[y1: y2, x1: x2] = 0.\n","\n","        mask = torch.from_numpy(mask)\n","        mask = mask.expand_as(img)\n","        img = img * mask\n","        return img\n","\n","class SubPolicy(object):\n","    def __init__(self, p1, operation1, magnitude_idx1, p2, operation2, magnitude_idx2, fillcolor=(128, 128, 128)):\n","        self.p1 = p1\n","        self.op1=operation1\n","        self.magnitude_idx1=magnitude_idx1\n","        self.p2 = p2\n","        self.op2=operation2\n","        self.magnitude_idx2=magnitude_idx2\n","        self.fillcolor=fillcolor\n","        self.init = 0\n","\n","    def gen(self, operation1, magnitude_idx1, operation2, magnitude_idx2, fillcolor):\n","        ranges = {\n","            \"shearX\": np.linspace(0, 0.3, 10),\n","            \"shearY\": np.linspace(0, 0.3, 10),\n","            \"translateX\": np.linspace(0, 150 / 331, 10),\n","            \"translateY\": np.linspace(0, 150 / 331, 10),\n","            \"rotate\": np.linspace(0, 30, 10),\n","            \"color\": np.linspace(0.0, 0.9, 10),\n","            \"posterize\": np.round(np.linspace(8, 4, 10), 0).astype(int),\n","            \"solarize\": np.linspace(256, 0, 10),\n","            \"contrast\": np.linspace(0.0, 0.9, 10),\n","            \"sharpness\": np.linspace(0.0, 0.9, 10),\n","            \"brightness\": np.linspace(0.0, 0.9, 10),\n","            \"autocontrast\": [0] * 10,\n","            \"equalize\": [0] * 10,\n","            \"invert\": [0] * 10\n","        }\n","        def rotate_with_fill(img, magnitude):\n","            rot = img.convert(\"RGBA\").rotate(magnitude)\n","            return Image.composite(rot, Image.new(\"RGBA\", rot.size, (128,) * 4), rot).convert(img.mode)\n","\n","        func = {\n","            \"shearX\": lambda img, magnitude: img.transform(\n","                img.size, Image.AFFINE, (1, magnitude *\n","                                         random.choice([-1, 1]), 0, 0, 1, 0),\n","                Image.BICUBIC, fillcolor=fillcolor),\n","            \"shearY\": lambda img, magnitude: img.transform(\n","                img.size, Image.AFFINE, (1, 0, 0, magnitude *\n","                                         random.choice([-1, 1]), 1, 0),\n","                Image.BICUBIC, fillcolor=fillcolor),\n","            \"translateX\": lambda img, magnitude: img.transform(\n","                img.size, Image.AFFINE, (1, 0, magnitude *\n","                                         img.size[0] * random.choice([-1, 1]), 0, 1, 0),\n","                fillcolor=fillcolor),\n","            \"translateY\": lambda img, magnitude: img.transform(\n","                img.size, Image.AFFINE, (1, 0, 0, 0, 1, magnitude *\n","                                         img.size[1] * random.choice([-1, 1])),\n","                fillcolor=fillcolor),\n","            \"rotate\": lambda img, magnitude: rotate_with_fill(img, magnitude),\n","            # \"rotate\": lambda img, magnitude: img.rotate(magnitude * random.choice([-1, 1])),\n","            \"color\": lambda img, magnitude: ImageEnhance.Color(img).enhance(1 + magnitude * random.choice([-1, 1])),\n","            \"posterize\": lambda img, magnitude: ImageOps.posterize(img, magnitude),\n","            \"solarize\": lambda img, magnitude: ImageOps.solarize(img, magnitude),\n","            \"contrast\": lambda img, magnitude: ImageEnhance.Contrast(img).enhance(\n","                1 + magnitude * random.choice([-1, 1])),\n","            \"sharpness\": lambda img, magnitude: ImageEnhance.Sharpness(img).enhance(\n","                1 + magnitude * random.choice([-1, 1])),\n","            \"brightness\": lambda img, magnitude: ImageEnhance.Brightness(img).enhance(\n","                1 + magnitude * random.choice([-1, 1])),\n","            \"autocontrast\": lambda img, magnitude: ImageOps.autocontrast(img),\n","            \"equalize\": lambda img, magnitude: ImageOps.equalize(img),\n","            \"invert\": lambda img, magnitude: ImageOps.invert(img)\n","        }\n","\n","        self.operation1 = func[operation1]\n","        self.magnitude1 = ranges[operation1][magnitude_idx1]\n","        self.operation2 = func[operation2]\n","        self.magnitude2 = ranges[operation2][magnitude_idx2]\n","\n","    def __call__(self, img):\n","        if self.init == 0:\n","            self.gen(self.op1, self.magnitude_idx1, self.op2, self.magnitude_idx2, self.fillcolor)\n","            self.init = 1\n","        if random.random() < self.p1:\n","            img = self.operation1(img, self.magnitude1)\n","        if random.random() < self.p2:\n","            img = self.operation2(img, self.magnitude2)\n","        return img\n","\n","class ImageNetPolicy(object):\n","    \"\"\" Randomly choose one of the best 24 Sub-policies on ImageNet.\n","        Example:\n","        >>> policy = ImageNetPolicy()\n","        >>> transformed = policy(image)\n","        Example as a PyTorch Transform:\n","        >>> transform=transforms.Compose([\n","        >>>     transforms.Resize(256),\n","        >>>     ImageNetPolicy(),\n","        >>>     transforms.ToTensor()])\n","    \"\"\"\n","\n","    def __init__(self, fillcolor=(128, 128, 128)):\n","        self.policies = [\n","            SubPolicy(0.4, \"posterize\", 8, 0.6, \"rotate\", 9, fillcolor),\n","            SubPolicy(0.6, \"solarize\", 5, 0.6, \"autocontrast\", 5, fillcolor),\n","            SubPolicy(0.8, \"equalize\", 8, 0.6, \"equalize\", 3, fillcolor),\n","            SubPolicy(0.6, \"posterize\", 7, 0.6, \"posterize\", 6, fillcolor),\n","            SubPolicy(0.4, \"equalize\", 7, 0.2, \"solarize\", 4, fillcolor),\n","\n","            SubPolicy(0.4, \"equalize\", 4, 0.8, \"rotate\", 8, fillcolor),\n","            SubPolicy(0.6, \"solarize\", 3, 0.6, \"equalize\", 7, fillcolor),\n","            SubPolicy(0.8, \"posterize\", 5, 1.0, \"equalize\", 2, fillcolor),\n","            SubPolicy(0.2, \"rotate\", 3, 0.6, \"solarize\", 8, fillcolor),\n","            SubPolicy(0.6, \"equalize\", 8, 0.4, \"posterize\", 6, fillcolor),\n","\n","            SubPolicy(0.8, \"rotate\", 8, 0.4, \"color\", 0, fillcolor),\n","            SubPolicy(0.4, \"rotate\", 9, 0.6, \"equalize\", 2, fillcolor),\n","            SubPolicy(0.0, \"equalize\", 7, 0.8, \"equalize\", 8, fillcolor),\n","            SubPolicy(0.6, \"invert\", 4, 1.0, \"equalize\", 8, fillcolor),\n","            SubPolicy(0.6, \"color\", 4, 1.0, \"contrast\", 8, fillcolor),\n","\n","            SubPolicy(0.8, \"rotate\", 8, 1.0, \"color\", 2, fillcolor),\n","            SubPolicy(0.8, \"color\", 8, 0.8, \"solarize\", 7, fillcolor),\n","            SubPolicy(0.4, \"sharpness\", 7, 0.6, \"invert\", 8, fillcolor),\n","            SubPolicy(0.6, \"shearX\", 5, 1.0, \"equalize\", 9, fillcolor),\n","            SubPolicy(0.4, \"color\", 0, 0.6, \"equalize\", 3, fillcolor),\n","\n","            SubPolicy(0.4, \"equalize\", 7, 0.2, \"solarize\", 4, fillcolor),\n","            SubPolicy(0.6, \"solarize\", 5, 0.6, \"autocontrast\", 5, fillcolor),\n","            SubPolicy(0.6, \"invert\", 4, 1.0, \"equalize\", 8, fillcolor),\n","            SubPolicy(0.6, \"color\", 4, 1.0, \"contrast\", 8, fillcolor)\n","        ]\n","\n","    def __call__(self, img):\n","        policy_idx = random.randint(0, len(self.policies) - 1)\n","        return self.policies[policy_idx](img)\n","\n","    def __repr__(self):\n","        return \"AutoAugment ImageNet Policy\"\n","\n","class CIFAR10Policy(object):\n","    \"\"\" Randomly choose one of the best 25 Sub-policies on CIFAR10.\n","\n","        Example:\n","        >>> policy = CIFAR10Policy()\n","        >>> transformed = policy(image)\n","\n","        Example as a PyTorch Transform:\n","        >>> transform=transforms.Compose([\n","        >>>     transforms.Resize(256),\n","        >>>     CIFAR10Policy(),\n","        >>>     transforms.ToTensor()])\n","    \"\"\"\n","\n","    def __init__(self, fillcolor=(128, 128, 128)):\n","        self.policies = [\n","            SubPolicy(0.1, \"invert\", 7, 0.2, \"contrast\", 6, fillcolor),\n","            SubPolicy(0.7, \"rotate\", 2, 0.3, \"translateX\", 9, fillcolor),\n","            SubPolicy(0.8, \"sharpness\", 1, 0.9, \"sharpness\", 3, fillcolor),\n","            SubPolicy(0.5, \"shearY\", 8, 0.7, \"translateY\", 9, fillcolor),\n","            SubPolicy(0.5, \"autocontrast\", 8, 0.9, \"equalize\", 2, fillcolor),\n","\n","            SubPolicy(0.2, \"shearY\", 7, 0.3, \"posterize\", 7, fillcolor),\n","            SubPolicy(0.4, \"color\", 3, 0.6, \"brightness\", 7, fillcolor),\n","            SubPolicy(0.3, \"sharpness\", 9, 0.7, \"brightness\", 9, fillcolor),\n","            SubPolicy(0.6, \"equalize\", 5, 0.5, \"equalize\", 1, fillcolor),\n","            SubPolicy(0.6, \"contrast\", 7, 0.6, \"sharpness\", 5, fillcolor),\n","\n","            SubPolicy(0.7, \"color\", 7, 0.5, \"translateX\", 8, fillcolor),\n","            SubPolicy(0.3, \"equalize\", 7, 0.4, \"autocontrast\", 8, fillcolor),\n","            SubPolicy(0.4, \"translateY\", 3, 0.2, \"sharpness\", 6, fillcolor),\n","            SubPolicy(0.9, \"brightness\", 6, 0.2, \"color\", 8, fillcolor),\n","            SubPolicy(0.5, \"solarize\", 2, 0.0, \"invert\", 3, fillcolor),\n","\n","            SubPolicy(0.2, \"equalize\", 0, 0.6, \"autocontrast\", 0, fillcolor),\n","            SubPolicy(0.2, \"equalize\", 8, 0.8, \"equalize\", 4, fillcolor),\n","            SubPolicy(0.9, \"color\", 9, 0.6, \"equalize\", 6, fillcolor),\n","            SubPolicy(0.8, \"autocontrast\", 4, 0.2, \"solarize\", 8, fillcolor),\n","            SubPolicy(0.1, \"brightness\", 3, 0.7, \"color\", 0, fillcolor),\n","\n","            SubPolicy(0.4, \"solarize\", 5, 0.9, \"autocontrast\", 3, fillcolor),\n","            SubPolicy(0.9, \"translateY\", 9, 0.7, \"translateY\", 9, fillcolor),\n","            SubPolicy(0.9, \"autocontrast\", 2, 0.8, \"solarize\", 3, fillcolor),\n","            SubPolicy(0.8, \"equalize\", 8, 0.1, \"invert\", 3, fillcolor),\n","            SubPolicy(0.7, \"translateY\", 9, 0.9, \"autocontrast\", 1, fillcolor)\n","        ]\n","\n","    def __call__(self, img):\n","        policy_idx = random.randint(0, len(self.policies) - 1)\n","        return self.policies[policy_idx](img)\n","\n","    def __repr__(self):\n","        return \"AutoAugment CIFAR10 Policy\"\n"],"metadata":{"id":"0m4DG18mQVuz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def GetCifar10(batchsize):\n","    trans_t = transforms.Compose([transforms.RandomCrop(32, padding=4),\n","                                  transforms.RandomHorizontalFlip(),\n","                                  # CIFAR10Policy(),\n","                                  transforms.ToTensor(),\n","                                  transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","                                  Cutout(n_holes=1, length=16)\n","                                  ])\n","    trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n","    train_data = datasets.CIFAR10('./data', train=True, transform=trans_t, download=True)\n","    test_data = datasets.CIFAR10('./data', train=False, transform=trans, download=True)\n","    train_dataloader = DataLoader(train_data, batch_size=batchsize, shuffle=True, num_workers=8)\n","    test_dataloader = DataLoader(test_data, batch_size=batchsize, shuffle=False, num_workers=8)\n","    return train_dataloader, test_dataloader"],"metadata":{"id":"oNhg5N9ARGqC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class VGG(nn.Module):\n","    def __init__(self, features, num_classes=10):\n","        super(VGG, self).__init__()\n","        self.features = features\n","        self.classifier = nn.Sequential(\n","            nn.Linear(128, num_classes),\n","        )\n","        self._initialize_weights()\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = F.adaptive_avg_pool2d(x, (1, 1))  # fixed output size\n","        x = torch.flatten(x, 1)\n","        x = self.classifier(x)\n","        return x\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","                m.weight.data.normal_(0, math.sqrt(2. / n))\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.Linear):\n","                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","def make_layers(cfg, batch_norm=False):\n","    layers = []\n","    in_channels = 3\n","    for v in cfg:\n","        if v == 'M':\n","            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n","        else:\n","            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n","            if batch_norm:\n","                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n","            else:\n","                layers += [conv2d, nn.ReLU(inplace=True)]\n","            in_channels = v\n","    return nn.Sequential(*layers)\n","\n","def vgg(cfg, num_classes=10, batch_norm=True):\n","    return VGG(make_layers(cfg, batch_norm=batch_norm), num_classes=num_classes)\n","\n","# VGG-6 configuration\n","cfg_vgg6 = [64, 64, 'M', 128, 128, 'M']\n","\n","model = vgg(cfg_vgg6, num_classes=10, batch_norm=True)\n","print(model)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8XTLRob5UwcZ","executionInfo":{"status":"ok","timestamp":1754902897386,"user_tz":-330,"elapsed":49,"user":{"displayName":"Rajshekhar Rakshit cs24s031","userId":"06985613993581015741"}},"outputId":"37d2ae84-6888-4f91-cd8f-9ad14b5b2b0b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU(inplace=True)\n","    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (9): ReLU(inplace=True)\n","    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (12): ReLU(inplace=True)\n","    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (classifier): Sequential(\n","    (0): Linear(in_features=128, out_features=10, bias=True)\n","  )\n",")\n"]}]},{"cell_type":"code","source":["def eval(model,data):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for data, target in data:\n","            data, target = data.to(device), target.to(device)\n","            outputs = model(data)\n","            _, predicted = outputs.max(1)\n","            total += target.size(0)\n","            correct += predicted.eq(target).sum().item()\n","    acc = 100. * correct / total\n","    return acc"],"metadata":{"id":"UcrlP6tGYWyL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_loader,test_loader = GetCifar10(64)"],"metadata":{"id":"yiWNCV7hWZ53"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"cLWPAqGGWjGW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = vgg(cfg_vgg6, num_classes=10, batch_norm=True).to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","lr = 0.001\n","epochs = 100\n","optimizer = optim.Adam(model.parameters(), lr=lr)\n"],"metadata":{"id":"YsnYElgwWpaI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_model(model,epochs,optimizer,train_loader,test_loader):\n","\n","    model.train()\n","    for epoch in range(epochs):\n","      running_loss = 0.0\n","      for data, target in train_loader:\n","          data, target = data.to(device), target.to(device)\n","          optimizer.zero_grad()\n","          outputs = model(data)\n","          loss = criterion(outputs, target)\n","          loss.backward()\n","          optimizer.step()\n","          running_loss += loss.item()\n","      train_acc = eval(model,train_loader)\n","      test_acc = eval(model,test_loader)\n","      print(f\"Epoch {epoch} - Train_Loss: {running_loss/len(train_loader):.4f} , Train_acc: {train_acc}, Test_acc : {test_acc}\")"],"metadata":{"id":"o4eSPJfRW6SL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_model(model,10,optimizer,train_loader,test_loader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ilmkf0okZuiB","executionInfo":{"status":"ok","timestamp":1754904030684,"user_tz":-330,"elapsed":436735,"user":{"displayName":"Rajshekhar Rakshit cs24s031","userId":"06985613993581015741"}},"outputId":"67be24cc-98a0-4b1b-e52b-9a9c5c880b12"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 0 - Train_Loss: 1.2534 , Train_acc: 51.79, Test_acc : 51.09\n","Epoch 1 - Train_Loss: 1.1252 , Train_acc: 65.558, Test_acc : 63.66\n","Epoch 2 - Train_Loss: 0.9455 , Train_acc: 69.15, Test_acc : 67.48\n","Epoch 3 - Train_Loss: 0.8459 , Train_acc: 71.112, Test_acc : 70.14\n","Epoch 4 - Train_Loss: 0.7741 , Train_acc: 72.782, Test_acc : 71.83\n","Epoch 5 - Train_Loss: 0.7169 , Train_acc: 77.528, Test_acc : 75.87\n","Epoch 6 - Train_Loss: 0.6669 , Train_acc: 75.414, Test_acc : 73.74\n","Epoch 7 - Train_Loss: 0.6260 , Train_acc: 78.746, Test_acc : 76.7\n","Epoch 8 - Train_Loss: 0.5907 , Train_acc: 81.344, Test_acc : 78.04\n","Epoch 9 - Train_Loss: 0.5573 , Train_acc: 81.562, Test_acc : 77.61\n"]}]},{"cell_type":"markdown","source":["##Task:\n","\n","    Change the network architecure, activation function , optimizer, learning rate ,etc. and record the performance of the model."],"metadata":{"id":"mxT0p-naa5WT"}},{"cell_type":"code","source":[],"metadata":{"id":"ewNedDvzZ2VB"},"execution_count":null,"outputs":[]}]}